{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset import Testset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    FactualCorrectness,\n",
    "    Faithfulness,\n",
    "    LLMContextRecall,\n",
    "    SemanticSimilarity,\n",
    "    NonLLMContextRecall,\n",
    "    LLMContextPrecisionWithReference,\n",
    "    NonLLMContextPrecisionWithReference,\n",
    "    ContextEntityRecall,\n",
    ")\n",
    "from docu_bot.utils import create_chatopenai_model, create_openai_embeddings\n",
    "from docu_bot.document_loaders.git_document_loader import GitDocumentLoader\n",
    "from docu_bot.document_loaders.utils import LoadedRepositoriesAndFiles\n",
    "from docu_bot.datasets.generate_synthetic_data_ragas import (\n",
    "    generate_dataset,\n",
    "    create_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"gpt-4o-mini\"\n",
    "api_key = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sythetic Datase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = LangchainLLMWrapper(create_chatopenai_model(model_type=model_type, api_key=api_key))\n",
    "embeddings_model = LangchainEmbeddingsWrapper(create_openai_embeddings())\n",
    "generator = create_generator(llm_model, embeddings_model)\n",
    "document_loader = GitDocumentLoader(\n",
    "    repo_path=\"https://github.com/jinymusim/serve-model.git\", branch=\"main\", loaded_repositories_and_files=LoadedRepositoriesAndFiles()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios: 100%|██████████| 1/1 [00:06<00:00,  6.96s/it] \n",
      "Generating Samples: 100%|██████████| 40/40 [00:07<00:00,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = generate_dataset(generator, document_loader.load(), dataset_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data.to_jsonl(\"synthetic_data.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USe Sythetic Data to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = Testset.from_jsonl(\"synthetic_data.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
